---
actor_ids:
  - kotone
  - soh
  - tadasu
  - coela
audio_file_path: https://traffic.libsyn.com/secure/researchat/52.mp3
audio_file_size: 70069134
date: 2020-04-12 11:14:00 +0900
description: ゲストにkotoneさんを招き、ディープラーニング、機械学習とそのアルゴリズムや計算用マシンについて話しました。
duration: "01:09:52"
layout: article
tags:
  - Deep Learning
  - アルゴリズム
  - 計算
title: 52. Split into a row
---

## Show notes
- [機械学習 (Wikipedia)](https://ja.wikipedia.org/wiki/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92)
- [ディープラーニング(深層学習) (Wikipedia)](https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0)
- [ニューラルネットワーク (Wikipedia)](https://ja.wikipedia.org/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)
- [パーセプトロン (Wikipedia)](https://ja.wikipedia.org/wiki/%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3)
- [GPU (Wikipedia)](https://ja.wikipedia.org/wiki/Graphics_Processing_Unit)
- [ディープラーニング入門 Chainer チュートリアル](https://tutorials.chainer.org/ja/)
- [株式会社 Preferred Networks](https://preferred.jp/ja/)
- [Chainer](https://tutorials.chainer.org/ja/)
- [NVIDIA CUDA-X GPU-Accelerated Libraries for AI and HPC](https://developer.nvidia.com/gpu-accelerated-libraries)
- [Preferred Networks、1024個のGPUでディープラーニングの世界最高速を実現と発表](https://it.impressbm.co.jp/articles/-/15271)
- [NARUTO -ナルト- 疾風伝](https://www.tv-tokyo.co.jp/anime/naruto/index2.html)
- [ナルト全巻セット](https://www.amazon.co.jp/gp/product/B07571D6J4/?tag=researchatf04-22)
- [ImageNet](http://www.image-net.org/)...学習用の画像データセット
- [畳み込みニューラルネット(Wikipedia)](https://ja.wikipedia.org/wiki/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)
- [THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/)...手書き文字認識用のデータセット
- [誤差逆伝播法 (Wikipedia)](https://ja.wikipedia.org/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3)...バックプロパゲーション
- [Data Parallelism VS Model Parallelism in Distributed Deep Learning Training](https://leimao.github.io/blog/Data-Parallelism-vs-Model-Paralelism/)...データ並列とモデル並列の違い
- [Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15 Minutes (arXiv)](https://arxiv.org/abs/1711.04325)...PFNが達成した超高効率データ並列学習
- [One weird trick for parallelizing convolutional neural networks (arXiv)](https://arxiv.org/abs/1404.5997)...畳み込みニューラルネットワークのモデル並列化
- [Performance Analysis of a Pipelined Backpropagation Parallel Algorithm (IEEE)](https://ieeexplore.ieee.org/abstract/document/286892)...パイプライン化による層並列化の検証
- [GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism (arXiv)](https://arxiv.org/abs/1811.06965)...マイクロバッチパイプライン化による層並列化の実装
- [Decoupled Neural Interfaces using Synthetic Gradients (arXiv)](https://arxiv.org/abs/1608.05343)...誤差逆伝播に必要な勾配を生成することで並列化可能とする学習手法
- [Direct Feedback Alignment Provides Learning in Deep Neural Networks (arXiv)](https://arxiv.org/abs/1609.01596)...層ごとの誤差逆伝播が不要な学習手法
- [Training Neural Networks with Local Error Signals (arXiv)](https://arxiv.org/abs/1901.06656)...大域的な誤差信号が不要な学習手法
- [スーパーコンピュータ「京」はとてつもなく速い](https://www.fujitsu.com/jp/about/businesspolicy/tech/k/whatis/system/)
- [スーパーコンピュータ「富岳」プロジェクト](https://www.r-ccs.riken.jp/jp/post-k/project.html)
- [スパコン撤去で「今は無き京前」？　駅名が話題](https://www.kobe-np.co.jp/news/sougou/201902/0012064729.shtml)
- [GUNSLINGER GIRL (全15巻)](https://www.amazon.co.jp/dp/B00UGJV7XO/?tag=researchatf04-22)...Kotoneさんおすすめのマンガ
- [Researchat.fm お便りフォーム](https://researchat.fm/form.html)...Researchat.fmではリスナーの方からのお便りを募集中です。よろしくお願いします。

## Editorial notes
- 生命科学の内容がメインのポッドキャストに呼んでいただきありがとうございました。とても楽しく収録させていただいたので皆さまにも楽しんでいただければ幸いです。いずれアイマスの話もリベンジしたいですね (kotone)
- 機械学習ネタ、これまでとは異なるテーマでとても良かったですね (soh)
- 他分野の話を聴くのは楽しい〜〜〜(tadasu)
- ことねさん出演ありがとうございました！音源が落ちてしまったアイマスの話もまた今度是非！(coela)
